# ğŸŒ¿ Manava-Swabhavalu

**Manava-Swabhavalu** (à°®à°¨à°µ à°¸à±à°µà°­à°¾à°µà°¾à°²à± â€” â€œHuman Natureâ€) is a research-driven, data-centric project aimed at laying the foundation for the first Telugu Large Language Model (LLM).  
The goal is to enable AI to *understand and generate Telugu content* that reflects **deep human emotions, personality traits, and cultural nuance**, rather than simply translating from other languages.

---

## ğŸ¯ Motivation & Vision

- **Why a Telugu LLM?**  
  Most existing language models focus on global or major languages, often missing out on the emotional richness and cultural context embedded in regional languages like Telugu. Manava-Swabhavalu aims to bridge that gap.

- **Beyond words â€” modeling human nature**  
  Rather than focusing solely on grammar or literal translation, this project seeks to represent how Telugu speakers express emotions, humor, empathy, sarcasm, cultural norms, and behavioral traits â€” enabling AI that resonates with native speakers.

---

## ğŸ“š What This Project Does

- Curates a **Telugu-centric dataset** capturing conversational and emotional language.  
- Defines an **annotation schema** to tag personality traits, emotional tone, cultural context.  
- Implements data cleaning, preprocessing, and tokenization pipelines tailored for Telugu.  
- Provides **reference scripts/notebooks** to train and evaluate models â€” aiming for a base model equipped for Telugu emotional and cultural understanding.  
- Documents methodology and guidelines to ensure **ethical, respectful, and culturally-sensitive** AI generation.

---

## ğŸ“ Repository Structure

Manava-Swabhavalu/
â”œâ”€â”€ README.md â† this file
â”œâ”€â”€ src/ â† source code, scripts, notebooks
â”‚ â”œâ”€â”€ data_preprocessing/
â”‚ â”œâ”€â”€ tokenization/
â”‚ â”œâ”€â”€ annotation_tools/
â”‚ â””â”€â”€ model_training/
â”œâ”€â”€ data/ â† raw and processed datasets (if included)
â”œâ”€â”€ docs/ â† project-documentation, annotation guidelines
â””â”€â”€ LICENSE

